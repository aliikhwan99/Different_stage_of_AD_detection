{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 9592054,
          "sourceType": "datasetVersion",
          "datasetId": 5850466
        }
      ],
      "dockerImageVersionId": 30786,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "Different_stage_of_AD_detection",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aliikhwan99/Different_stage_of_AD_detection/blob/main/Different_stage_of_AD_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'stage-of-alzheimer:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F5850466%2F9592054%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20241014%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20241014T014818Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D81843272db38bc3ba676e8005e39cd49a38b0c8684382be1dfec57d53e295153fabcd2b787a9958c224a3d0beb4c4d82d8c8bb5350f728034114f286b5ac4e6ebb7298b809f739e67c945e84308e926e05893d2ddd246a966e11f740855f714c2c8c719510551dc7dcd6133092c9790318a7c2c7855c37626b64e0855d801c40b8e55f477806d849dcb5120ab13de12fedc14bb709866a2fee14ccb9bce1f866d5077a9cc55c33f5918af253a45133e088d2394822f78c8fa8cdac336baf1644fa70373f59eb961fa44b84dce0be43fb2932e59e07bb42747bee87beb48f7a743e97eeb6ee061f95e370530c3b905fc02aa607753dd84861ac4cc88878bf270c'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "2IsMTK-RtkzH"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# visulize rs-fMRI"
      ],
      "metadata": {
        "id": "7HxLAe8RtkzK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Averaging the fMRI image across time\n",
        "fmri_img_mean = image.mean_img(fmri_img)\n",
        "\n",
        "# Project to surface\n",
        "texture_left = surface.vol_to_surf(fmri_img_mean, fsaverage.pial_left)\n",
        "texture_right = surface.vol_to_surf(fmri_img_mean, fsaverage.pial_right)\n",
        "\n",
        "# Plot the projected data\n",
        "plotting.plot_surf_stat_map(fsaverage.infl_left, texture_left, hemi='left', title='Left Hemisphere')\n",
        "plotting.plot_surf_stat_map(fsaverage.infl_right, texture_right, hemi='right', title='Right Hemisphere')\n",
        "\n",
        "plotting.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "p6Hjp9SKtkzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ORGIGIN"
      ],
      "metadata": {
        "id": "06UMQWSTtkzN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y dcm2niix\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "i40qTLVBtkzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "\n",
        "dicom_directory = '/kaggle/input/stage-of-alzheimer/NC/ADNI/002_S_0295/Resting_State_fMRI/2011-06-02_07_56_36.0/I238623'\n",
        "output_directory = '/kaggle/working'  # Specify where you want to save the NIfTI file\n",
        "\n",
        "# Run dcm2niix and capture output and error messages\n",
        "result = subprocess.run(['dcm2niix', '-z', 'y', '-f', '%p_%s', '-o', output_directory, dicom_directory],\n",
        "                        capture_output=True, text=True)\n",
        "\n",
        "# Print the output and error messages\n",
        "print(\"Output:\\n\", result.stdout)\n",
        "print(\"Error:\\n\", result.stderr)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "iHQq4K7ItkzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y dcm2niix\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "p5UyH-C6tkzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "print(\"Converted files:\")\n",
        "print(os.listdir(output_directory))\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "mGTJ3g0DtkzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nilearn import image, plotting\n",
        "\n",
        "# Load the NIfTI file\n",
        "nifti_file = os.path.join(output_directory, 'Resting_State_fMRI_501a.nii.gz')\n",
        "img = image.load_img(nifti_file)\n",
        "\n",
        "# Extract the first time point (index 0)\n",
        "first_time_point = img.slicer[..., 0]  # Select the first time point\n",
        "\n",
        "# Visualize the first time point\n",
        "plotting.plot_img(first_time_point, display_mode='z', cut_coords=[-20, -10, 0])\n",
        "plotting.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "_a__MAN5tkzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nilearn import image, plotting\n",
        "\n",
        "# Load the NIfTI file\n",
        "nifti_file = os.path.join(output_directory, 'Resting_State_fMRI_501a.nii.gz')\n",
        "img = image.load_img(nifti_file)\n",
        "\n",
        "# Compute the mean across all time points\n",
        "mean_img = image.mean_img(img)\n",
        "\n",
        "# Visualize the mean image\n",
        "plotting.plot_img(mean_img, display_mode='z', cut_coords=[-20, -10, 0])\n",
        "plotting.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "SG3_yn7BtkzQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Normal"
      ],
      "metadata": {
        "id": "-ngrVpNNtkzQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualizing the Connectivity Matrix"
      ],
      "metadata": {
        "id": "fYAO7L8XtkzQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "HToMj3LKtkzQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# varation 2"
      ],
      "metadata": {
        "id": "hhfTeuh4tkzQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pydicom  # Make sure pydicom is installed in your environment\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from nilearn import datasets\n",
        "from scipy.ndimage import gaussian_filter  # Import Gaussian filter\n",
        "\n",
        "# Path to the directory containing the DICOM files\n",
        "dicom_directory = '/kaggle/input/stage-of-alzheimer/NC/ADNI/002_S_0295/Resting_State_fMRI/2011-06-02_07_56_36.0/I238623'\n",
        "\n",
        "# Check if the directory exists\n",
        "if not os.path.exists(dicom_directory):\n",
        "    print(f\"Directory not found: {dicom_directory}\")\n",
        "else:\n",
        "    print(f\"Directory exists: {dicom_directory}\")\n",
        "\n",
        "    # Load the DICOM files\n",
        "    def load_dicom_series(directory):\n",
        "        dicom_files = [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith('.dcm')]\n",
        "        dicom_files.sort()  # Sort the files to maintain order\n",
        "        images = []\n",
        "        for dicom_file in dicom_files:\n",
        "            ds = pydicom.dcmread(dicom_file)\n",
        "            images.append(ds.pixel_array)  # Append pixel data\n",
        "        return np.array(images)\n",
        "\n",
        "    # Load your fMRI data\n",
        "    fmri_data = load_dicom_series(dicom_directory)\n",
        "    print(f\"Shape of fMRI data: {fmri_data.shape}\")  # (time_points, height, width)\n",
        "\n",
        "# Function to extract time series from the 4D fMRI data\n",
        "def extract_time_series(fmri_data):\n",
        "    # Get the shape of the fMRI data\n",
        "    time_points, height, width = fmri_data.shape[0], fmri_data.shape[1], fmri_data.shape[2]\n",
        "\n",
        "    # Reshape to a 2D array: (voxels, time_points)\n",
        "    reshaped_data = fmri_data.reshape(-1, time_points)\n",
        "    return reshaped_data\n",
        "\n",
        "# Extract time series from the fMRI data\n",
        "time_series = extract_time_series(fmri_data)\n",
        "print(f\"Shape of time series data: {time_series.shape}\")  # (voxels, time_points)\n",
        "\n",
        "# Function to compute the functional connectivity matrix\n",
        "def compute_functional_connectivity(time_series):\n",
        "    # Calculate the correlation matrix\n",
        "    connectivity_matrix = np.corrcoef(time_series)\n",
        "    return connectivity_matrix\n",
        "\n",
        "# Compute the functional connectivity matrix\n",
        "connectivity_matrix = compute_functional_connectivity(time_series)\n",
        "print(f\"Shape of connectivity matrix: {connectivity_matrix.shape}\")  # (voxels, voxels)\n",
        "\n",
        "# Apply Gaussian filter to the functional connectivity matrix\n",
        "smoothed_connectivity_matrix = gaussian_filter(connectivity_matrix, sigma=2)  # You can adjust sigma value\n",
        "\n",
        "# Load the AAL brain atlas and its labels\n",
        "atlas = datasets.fetch_atlas_aal()\n",
        "atlas_labels = atlas['labels']  # Get brain region labels\n",
        "\n",
        "# Truncate the connectivity matrix if it's larger than the number of available atlas labels\n",
        "num_labels = len(atlas_labels)\n",
        "if smoothed_connectivity_matrix.shape[0] > num_labels:\n",
        "    truncated_connectivity_matrix = smoothed_connectivity_matrix[:num_labels, :num_labels]\n",
        "else:\n",
        "    truncated_connectivity_matrix = smoothed_connectivity_matrix  # Use the original if no truncation needed\n",
        "\n",
        "# Function to plot a clearer connectivity matrix with enhancements\n",
        "def plot_enhanced_connectivity_matrix(connectivity_matrix, labels):\n",
        "    plt.figure(figsize=(14, 12), dpi=100)  # Increase size and DPI\n",
        "    sns.set(font_scale=1)  # Increase font scale for better readability\n",
        "    sns.heatmap(connectivity_matrix, cmap='coolwarm', square=True,\n",
        "                xticklabels=labels[:connectivity_matrix.shape[0]],\n",
        "                yticklabels=labels[:connectivity_matrix.shape[0]],\n",
        "                cbar_kws={\"shrink\": .4}, linewidths=.2)  # Add lines between cells for clarity\n",
        "    plt.title('Functional Connectivity Matrix (Enhanced)', fontsize=5)\n",
        "    plt.xlabel('Brain Regions', fontsize=4)\n",
        "    plt.ylabel('Brain Regions', fontsize=4)\n",
        "    plt.xticks(rotation=90)  # Rotate x-axis labels for better readability\n",
        "    plt.tight_layout()  # Adjust layout to fit everything well\n",
        "    plt.show()\n",
        "\n",
        "# Plot the enhanced connectivity matrix with the AAL labels\n",
        "plot_enhanced_connectivity_matrix(truncated_connectivity_matrix, atlas_labels)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "yWBt_5KEtkzR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pydicom  # Make sure pydicom is installed in your environment\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from nilearn import datasets\n",
        "from scipy.ndimage import gaussian_filter  # Import Gaussian filter\n",
        "from scipy.ndimage import median_filter\n",
        "\n",
        "# Path to the directory containing the DICOM files\n",
        "dicom_directory = '/kaggle/input/stage-of-alzheimer/NC/ADNI/002_S_0295/Resting_State_fMRI/2011-06-02_07_56_36.0/I238623'\n",
        "\n",
        "# Check if the directory exists\n",
        "if not os.path.exists(dicom_directory):\n",
        "    print(f\"Directory not found: {dicom_directory}\")\n",
        "else:\n",
        "    print(f\"Directory exists: {dicom_directory}\")\n",
        "\n",
        "    # Load the DICOM files\n",
        "    def load_dicom_series(directory):\n",
        "        dicom_files = [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith('.dcm')]\n",
        "        dicom_files.sort()  # Sort the files to maintain order\n",
        "        images = []\n",
        "        for dicom_file in dicom_files:\n",
        "            ds = pydicom.dcmread(dicom_file)\n",
        "            images.append(ds.pixel_array)  # Append pixel data\n",
        "        return np.array(images)\n",
        "\n",
        "    # Load your fMRI data\n",
        "    fmri_data = load_dicom_series(dicom_directory)\n",
        "    print(f\"Shape of fMRI data: {fmri_data.shape}\")  # (time_points, height, width)\n",
        "\n",
        "# Function to extract time series from the 4D fMRI data\n",
        "def extract_time_series(fmri_data):\n",
        "    # Get the shape of the fMRI data\n",
        "    time_points, height, width = fmri_data.shape[0], fmri_data.shape[1], fmri_data.shape[2]\n",
        "\n",
        "    # Reshape to a 2D array: (voxels, time_points)\n",
        "    reshaped_data = fmri_data.reshape(-1, time_points)\n",
        "    return reshaped_data\n",
        "\n",
        "# Extract time series from the fMRI data\n",
        "time_series = extract_time_series(fmri_data)\n",
        "print(f\"Shape of time series data: {time_series.shape}\")  # (voxels, time_points)\n",
        "\n",
        "# Function to compute the functional connectivity matrix\n",
        "def compute_functional_connectivity(time_series):\n",
        "    # Calculate the correlation matrix\n",
        "    connectivity_matrix = np.corrcoef(time_series)\n",
        "    return connectivity_matrix\n",
        "\n",
        "# Apply median filter to reduce noise\n",
        "filtered_matrix = median_filter(connectivity_matrix, size=3)  # Adjust size for the window size\n",
        "\n",
        "# Compute the functional connectivity matrix\n",
        "connectivity_matrix = compute_functional_connectivity(time_series)\n",
        "print(f\"Shape of connectivity matrix: {connectivity_matrix.shape}\")  # (voxels, voxels)\n",
        "\n",
        "# Apply Gaussian filter to the functional connectivity matrix\n",
        "smoothed_connectivity_matrix = gaussian_filter(connectivity_matrix, sigma=3)  # You can adjust sigma value\n",
        "\n",
        "# Load the AAL brain atlas and its labels\n",
        "atlas = datasets.fetch_atlas_aal()\n",
        "atlas_labels = atlas['labels']  # Get brain region labels\n",
        "\n",
        "# Truncate the connectivity matrix if it's larger than the number of available atlas labels\n",
        "num_labels = len(atlas_labels)\n",
        "if smoothed_connectivity_matrix.shape[0] > num_labels:\n",
        "    truncated_connectivity_matrix = smoothed_connectivity_matrix[:num_labels, :num_labels]\n",
        "else:\n",
        "    truncated_connectivity_matrix = smoothed_connectivity_matrix  # Use the original if no truncation needed\n",
        "\n",
        "# Function to plot a clearer connectivity matrix with enhancements\n",
        "def plot_enhanced_connectivity_matrix(connectivity_matrix, labels):\n",
        "    plt.figure(figsize=(14, 12), dpi=100)  # Increase size and DPI\n",
        "    sns.set(font_scale=1)  # Increase font scale for better readability\n",
        "    sns.heatmap(connectivity_matrix, cmap='coolwarm', square=True,\n",
        "                xticklabels=labels[:connectivity_matrix.shape[0]],\n",
        "                yticklabels=labels[:connectivity_matrix.shape[0]],\n",
        "                cbar_kws={\"shrink\": .4}, linewidths=.2)  # Add lines between cells for clarity\n",
        "    plt.title('Functional Connectivity Matrix (Enhanced)', fontsize=5)\n",
        "    plt.xlabel('Brain Regions', fontsize=4)\n",
        "    plt.ylabel('Brain Regions', fontsize=4)\n",
        "    plt.xticks(rotation=90)  # Rotate x-axis labels for better readability\n",
        "    plt.tight_layout()  # Adjust layout to fit everything well\n",
        "    plt.show()\n",
        "\n",
        "# Plot the enhanced connectivity matrix with the AAL labels\n",
        "plot_enhanced_connectivity_matrix(truncated_connectivity_matrix, atlas_labels)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "5d8FLDZItkzR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Actual brain activity position"
      ],
      "metadata": {
        "id": "MV_MP-OytkzR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nilearn matplotlib\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "zA_RlJYetkzS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from nilearn import plotting, datasets, surface\n",
        "from nilearn.input_data import NiftiLabelsMasker\n",
        "\n",
        "# Mock example of your connectivity matrix; replace with your actual matrix\n",
        "connectivity_matrix = np.random.rand(90, 90)  # Example connectivity matrix (90 regions)\n",
        "\n",
        "# Load the AAL atlas\n",
        "atlas = datasets.fetch_atlas_aal()\n",
        "atlas_filename = atlas['maps']  # AAL atlas NIfTI file\n",
        "atlas_labels = atlas['labels']  # Get brain region labels\n",
        "\n",
        "# Load a standard brain surface for visualization\n",
        "fsaverage = datasets.fetch_surf_fsaverage()\n",
        "\n",
        "# Use NiftiLabelsMasker to extract time series data based on atlas regions\n",
        "masker = NiftiLabelsMasker(labels_img=atlas_filename, standardize=True)\n",
        "\n",
        "# Prepare a 1D array to represent the functional connectivity on the brain surface\n",
        "left_connectivity = np.zeros(45)  # For left hemisphere\n",
        "right_connectivity = np.zeros(45)  # For right hemisphere\n",
        "\n",
        "# Map connectivity values to left and right hemispheres\n",
        "for i in range(len(atlas_labels)):\n",
        "    if i < 45:  # Left hemisphere\n",
        "        left_connectivity[i] = connectivity_matrix[i, :].mean()  # Example aggregation\n",
        "    elif i < 90:  # Right hemisphere\n",
        "        right_index = i - 45  # Adjust index for right hemisphere\n",
        "        right_connectivity[right_index] = connectivity_matrix[i, :].mean()  # Example aggregation\n",
        "\n",
        "# Project the AAL atlas regions onto the brain surface\n",
        "texture_left = surface.vol_to_surf(atlas_filename, fsaverage.pial_left)\n",
        "texture_right = surface.vol_to_surf(atlas_filename, fsaverage.pial_right)\n",
        "\n",
        "# Plot the left hemisphere\n",
        "plotting.plot_surf_stat_map(fsaverage['infl_left'],\n",
        "                            stat_map=texture_left,\n",
        "                            hemi='left',\n",
        "                            view='lateral',\n",
        "                            title='Left Hemisphere',\n",
        "                            colorbar=True)\n",
        "\n",
        "# Plot the right hemisphere\n",
        "plotting.plot_surf_stat_map(fsaverage['infl_right'],\n",
        "                            stat_map=texture_right,\n",
        "                            hemi='right',\n",
        "                            view='lateral',\n",
        "                            title='Right Hemisphere',\n",
        "                            colorbar=True)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "fs3neBcgtkzS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "# Plot using the correct 3D axes\n",
        "plotting.plot_surf_stat_map(\n",
        "    fsaverage['infl_left'],\n",
        "    stat_map=left_connectivity,\n",
        "    view='lateral',\n",
        "    threshold=0.1,\n",
        "    colorbar=True,\n",
        "    title='Functional Connectivity (Left Hemisphere)',\n",
        "    axes=ax\n",
        ")\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "wgsG01--tkzS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LMCI"
      ],
      "metadata": {
        "id": "Z5Bph8IGtkzS"
      }
    }
  ]
}